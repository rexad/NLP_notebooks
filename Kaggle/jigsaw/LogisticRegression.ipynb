{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegression.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOlJhuvXn2Av4AqwfYZDLBO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rexad/NLP_notebooks/blob/master/Kaggle/jigsaw/LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVcJF9NdUQKh",
        "colab_type": "text"
      },
      "source": [
        "#logistic regression with Scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9q4W6qv-UWIL",
        "colab_type": "text"
      },
      "source": [
        "##Importing our libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW8ry6kAbwDp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwDOa0J4T2E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "import gensim.downloader as api\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "import os.path\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csCWaSH1ZmA4",
        "colab_type": "text"
      },
      "source": [
        "##Load data for jigsaw "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DDNABw5ZbqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "663a9d87-c00d-4f23-8931-ab02f2db3fc3"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "!ls \"/content/gdrive/My Drive/\"\n",
        "train = pd.read_csv('/content/gdrive/My Drive/Data/jigsaw-unintended-bias-in-toxicity-classification/train.csv')\n",
        "test = pd.read_csv('/content/gdrive/My Drive/Data/jigsaw-unintended-bias-in-toxicity-classification/test.csv')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'Colab Notebooks'   Data\t\t\t\t\t ML_Training\n",
            " Colab_Notebooks   'Machine Learning A-Z (Codes and Datasets)'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qQN1y8nZxUD",
        "colab_type": "text"
      },
      "source": [
        "##Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whJQXh9p-DSJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 220"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJyVADYOlkIG",
        "colab_type": "text"
      },
      "source": [
        "###Generate features with embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ismjlNL4b31n",
        "colab_type": "text"
      },
      "source": [
        "####Load embeddings using gensim library "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdqLozPKb-c9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_path_embed = '/content/gdrive/My Drive/Data/Embeddings/'\n",
        "embeddings = [\n",
        "              'fasttext-wiki-news-subwords-300',\n",
        "              'glove-twitter-100',\n",
        "              'glove-wiki-gigaword-300'\n",
        "              ]\n",
        "for embed in embeddings:\n",
        "  if os.path.isfile(base_path_embed+embed) == False:\n",
        "    embed_file = api.load(embed)\n",
        "    embed_file.save(base_path_embed+embed)\n",
        "    del embed_file"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2xl53iKcI7_",
        "colab_type": "text"
      },
      "source": [
        "####Extract text information and tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwYPvLf9ZsAW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "spcial_carracter = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "    num_words=None, split= ' ', filters = spcial_carracter\n",
        ")\n",
        "tokenizer.fit_on_texts(list(train['comment_text']) + list(test['comment_text']))\n",
        "x_train = tokenizer.texts_to_sequences(train['comment_text'])\n",
        "x_test = tokenizer.texts_to_sequences(test['comment_text'])\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=max_length)\n",
        "y_train = np.where(train['target'] > 0.5, 1, 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qowlG5kb_e-",
        "colab_type": "text"
      },
      "source": [
        "####Build embedding matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JYIW8EpcIMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_embed_matrix(embed, tokens):\n",
        "\n",
        "  embed_vec = KeyedVectors.load(base_path_embed + embed, mmap='r')\n",
        "  embed_matrix = np.zeros((len(tokens) + 1,300))\n",
        "  for i, word in tokens.items():\n",
        "    for candidate in [word, word.lower()]:\n",
        "      if candidate in embed_vec:\n",
        "        embed_matrix[i]= embed_vec[candidate]\n",
        "  return embed_matrix"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3aFS0_qW-nfC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "47627d31-00a5-4ec1-cb9d-02a9d0dca5f8"
      },
      "source": [
        "embed_matrix = build_embed_matrix('fasttext-wiki-news-subwords-300', tokenizer.index_word)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80RqqDSSl7aa",
        "colab_type": "text"
      },
      "source": [
        "####Genrate emebddings for the data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKJ4Ng1qkmiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_feature_embed_mean(embed_matrix, features):\n",
        "  temp = []\n",
        "  feature_embed = np.zeros((features.shape[0],300))\n",
        "\n",
        "  for i in range(features.shape[0]):\n",
        "    for j in range(features.shape[1]):\n",
        "      temp.append(embed_matrix[features[i][j]])\n",
        "    feature_embed[i] = np.mean(temp, axis=0)\n",
        "    temp = []\n",
        "    return feature_embed"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5WCeRP_hcWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_feature_embed_min_max(embed_matrix, features):\n",
        "  temp = []\n",
        "  feature_embed = np.zeros((features.shape[0],600))\n",
        "\n",
        "  for i in range(features.shape[0]):\n",
        "    for j in range(features.shape[1]):\n",
        "      temp.append(embed_matrix[features[i][j]])\n",
        "    feature_embed[i] = np.minimum(temp, axis=0) + np.maximum(temp, axis=0)\n",
        "    temp = []\n",
        "    return feature_embed"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N-OGfP0j4XX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_feature = build_feature_embed_mean(embed_matrix, x_train)\n",
        "x_test_feature = build_feature_embed_mean(embed_matrix, x_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJKmRtCllU4s",
        "colab_type": "text"
      },
      "source": [
        "###Generate tf-idf features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6WdwnbrlXvM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
        "def tokenize(s): return text.sub(r' \\1 ', s).split()\n",
        "length = train_df.shape[0]\n",
        "Vectorize = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
        "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
        "               smooth_idf=1, sublinear_tf=1 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmVZD18iiY0B",
        "colab_type": "text"
      },
      "source": [
        "##Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxRdNbt1iX90",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJGe4NbxjHSa",
        "colab_type": "text"
      },
      "source": [
        "## test the result "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gND3vNdrjJJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}